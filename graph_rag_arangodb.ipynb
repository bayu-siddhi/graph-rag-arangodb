{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkolivegreen;font-weight:800;font-size:32px\">\n",
    "    Building Agentic Apps: ArangoDB, NVIDIA cuGraph, and NetworkX Hackathon\n",
    "</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://arangodb.com/wp-content/uploads/2016/05/ArangoDB_logo_avocado_@1.png\" style=\"height: 50px;\">\n",
    "    <img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/02-nvidia-logo-color-grn-500x200-4c25-p@2x.png\" style=\"height: 50px;\">\n",
    "    <img src=\"https://rapids.ai/images/RAPIDS-logo.png\" style=\"height: 50px;\">\n",
    "    <img src=\"https://avatars.githubusercontent.com/u/388785?s=200&v=4\" style=\"height: 50px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 0**: Package Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install all requirements via pip\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check if you have an NVIDIA GPU\n",
    "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
    "\n",
    "# !nvidia-smi\n",
    "# !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Install nx-cugraph via pip, requires CUDA-capable GPU\n",
    "# Note: Only enable this installation if the step above is working!\n",
    "\n",
    "# !pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Import the required modules\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1**: Prepare and Load Dataset for `NetworkX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dict_to_json(data: list[dict], output_path: str) -> None:\n",
    "    if not output_path.endswith(\".json\"):\n",
    "        output_path = f\"{output_path}.json\"\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        json.dump(data, output_file, indent=4)\n",
    "\n",
    "\n",
    "def load_dataset_from_dir(dir_path: str) -> dict[str, pd.DataFrame]:\n",
    "    json_data = {}\n",
    "    json_files = sorted([file for file in os.listdir(dir_path) if file.endswith(\".json\")], reverse=True)\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(dir_path, json_file), \"r\", encoding=\"utf-8\") as file:\n",
    "            json_data[os.path.splitext(json_file)[0]] = json.load(file)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "def prepare_regulation_data(regulation_data: list[dict], output_dir: str, verbose: bool = True) -> None:\n",
    "    result = {\n",
    "    # Node\n",
    "        \"node_Regulation\": [],\n",
    "        \"node_Consideration\": [],\n",
    "        \"node_Observation\": [],\n",
    "        \"node_Article\": [],\n",
    "        \"node_Definition\": [],\n",
    "    # Relationship\n",
    "        \"edge_reg_AMENDED_BY\": [],\n",
    "        \"edge_HAS_CONSIDERATION\": [],\n",
    "        \"edge_HAS_OBSERVATION\": [],\n",
    "        \"edge_HAS_DEFINITION\": [],\n",
    "        \"edge_HAS_ARTICLE\": [],\n",
    "        \"edge_NEXT_ARTICLE\": [],\n",
    "        \"edge_REFER_TO\": [],\n",
    "        \"edge_art_AMENDED_BY\": [],\n",
    "    }\n",
    "\n",
    "    edge_NEXT_ARTICLE_1 = []\n",
    "    edge_NEXT_ARTICLE_2 = []\n",
    "\n",
    "    for regulation in tqdm(iterable=regulation_data, desc=\"Transform regulation data\", disable=not verbose):\n",
    "        result[\"node_Regulation\"].append({\n",
    "            \"id\": int(regulation[\"id\"]),\n",
    "            \"title\": regulation[\"title\"],\n",
    "            \"about\": regulation[\"about\"],\n",
    "            \"type\": regulation[\"type\"],\n",
    "            \"number\": int(regulation[\"number\"]),\n",
    "            \"year\": int(regulation[\"year\"]),\n",
    "            \"is_amendment\": bool(int(regulation[\"amendment\"])),\n",
    "            \"amendment_order\": int(regulation[\"amendment\"]),\n",
    "            \"institution\": regulation[\"institution\"],\n",
    "            \"issue_place\": regulation[\"issue_place\"],\n",
    "            \"issue_date\": regulation[\"issue_date\"] if regulation[\"issue_date\"] else None,\n",
    "            \"effective_date\": regulation[\"effective_date\"] if regulation[\"effective_date\"] else None,\n",
    "            \"subjects\": regulation[\"subjects\"],\n",
    "            \"reference_url\": regulation[\"url\"],\n",
    "            \"download_url\": regulation[\"download_link\"],\n",
    "            \"download_name\": regulation[\"download_name\"]\n",
    "        })\n",
    "\n",
    "        for amended_regulation in regulation[\"status\"][\"amend\"]:\n",
    "            if re.search(r\"peraturan\\.bpk\\.go\\.id\", amended_regulation, re.IGNORECASE) is None:\n",
    "                result[\"edge_reg_AMENDED_BY\"].append({\n",
    "                    \"from_type\": \"Regulation\",\n",
    "                    \"from\": int(regulation[\"id\"]),\n",
    "                    \"to_type\": \"Regulation\",\n",
    "                    \"to\": int(amended_regulation)\n",
    "                })\n",
    "\n",
    "        for key, content in regulation[\"content\"].items():\n",
    "            if key == \"considering\":\n",
    "                result[\"node_Consideration\"].append({\n",
    "                    \"id\": int(content[\"id\"]),\n",
    "                    \"text\": content[\"text\"]\n",
    "                })\n",
    "\n",
    "                result[\"edge_HAS_CONSIDERATION\"].append({\n",
    "                    \"from_type\": \"Regulation\",\n",
    "                    \"from\": int(regulation[\"id\"]),\n",
    "                    \"to_type\": \"Consideration\",\n",
    "                    \"to\": int(content[\"id\"])\n",
    "                })\n",
    "\n",
    "            elif key == \"observing\":\n",
    "                result[\"node_Observation\"].append({\n",
    "                    \"id\": int(content[\"id\"]),\n",
    "                    \"text\": content[\"text\"]\n",
    "                })\n",
    "\n",
    "                result[\"edge_HAS_OBSERVATION\"].append({\n",
    "                    \"from_type\": \"Regulation\",\n",
    "                    \"from\": int(regulation[\"id\"]),\n",
    "                    \"to_type\": \"Observation\",\n",
    "                    \"to\": int(content[\"id\"])\n",
    "                })\n",
    "\n",
    "            elif key == \"articles\":\n",
    "                for article in content.values():\n",
    "                    text = (\n",
    "                        f\"{regulation['title']}, \"\n",
    "                        f\"{(article['chapter_about'] or '') + ', ' if article['chapter_about'] else ''}\"\n",
    "                        f\"{(article['part_about'] or '') + ', ' if article['part_about'] else ''}\"\n",
    "                        f\"{(article['paragraph_about'] or '') + ', ' if article['paragraph_about'] else ''}\"\n",
    "                        f\"Pasal {article['article_number']}:\\n\"\n",
    "                        f\"{article['text']}\".strip()\n",
    "                    )\n",
    "\n",
    "                    result[\"node_Article\"].append({\n",
    "                        \"id\": int(article[\"id\"]),\n",
    "                        \"number\": article[\"article_number\"],\n",
    "                        \"chapter\": article[\"chapter_number\"] if article[\"chapter_number\"] else None,\n",
    "                        \"part\": article[\"part_number\"] if article[\"part_number\"] else None,\n",
    "                        \"paragraph\": article[\"paragraph_number\"] if article[\"paragraph_number\"] else None,\n",
    "                        \"text\": text\n",
    "                    })\n",
    "\n",
    "                    result[\"edge_HAS_ARTICLE\"].append({\n",
    "                        \"from_type\": \"Regulation\",\n",
    "                        \"from\": int(regulation[\"id\"]),\n",
    "                        \"to_type\": \"Article\",\n",
    "                        \"to\": int(article[\"id\"])\n",
    "                    })\n",
    "\n",
    "                    if article[\"previous_article\"]:\n",
    "                        edge_NEXT_ARTICLE_1.append((\n",
    "                            int(article[\"previous_article\"]),\n",
    "                            int(article[\"id\"]),\n",
    "                            int(regulation[\"amendment\"])\n",
    "                        ))\n",
    "\n",
    "                    if article[\"next_article\"]:\n",
    "                        edge_NEXT_ARTICLE_2.append((\n",
    "                            int(article[\"id\"]),\n",
    "                            int(article[\"next_article\"]),\n",
    "                            int(regulation[\"amendment\"])\n",
    "                        ))\n",
    "\n",
    "                    if article[\"references\"]:\n",
    "                        for reference_article_id in article[\"references\"]:\n",
    "                            result[\"edge_REFER_TO\"].append({\n",
    "                                \"from_type\": \"Article\",\n",
    "                                \"from\": int(article[\"id\"]),\n",
    "                                \"to_type\": \"Article\",\n",
    "                                \"to\": int(reference_article_id)\n",
    "                            })\n",
    "\n",
    "                    if article[\"amend\"]:\n",
    "                        for amended_article_id in article[\"amend\"]:\n",
    "                            result[\"edge_art_AMENDED_BY\"].append({\n",
    "                                \"from_type\": \"Article\",\n",
    "                                \"from\": int(article[\"id\"]),\n",
    "                                \"to_type\": \"Article\",\n",
    "                                \"to\": int(amended_article_id)\n",
    "                            })\n",
    "\n",
    "            else:\n",
    "                for definition in content:\n",
    "                    text = (\n",
    "                        f\"{regulation['title']}, \"\n",
    "                        f\"Definisi {definition['name']}:\\n\"\n",
    "                        f\"{definition['definition']}\".strip()\n",
    "                    )\n",
    "\n",
    "                    result[\"node_Definition\"].append({\n",
    "                        \"id\": int(definition[\"id\"]),\n",
    "                        \"name\": definition[\"name\"],\n",
    "                        \"text\": text,\n",
    "                    })\n",
    "\n",
    "                    result[\"edge_HAS_DEFINITION\"].append({\n",
    "                        \"from_type\": \"Regulation\",\n",
    "                        \"from\": int(regulation[\"id\"]),\n",
    "                        \"to_type\": \"Definition\",\n",
    "                        \"to\": int(definition[\"id\"])\n",
    "                    })\n",
    "\n",
    "    for edge in sorted(set(edge_NEXT_ARTICLE_1 + edge_NEXT_ARTICLE_2)):\n",
    "        result[\"edge_NEXT_ARTICLE\"].append({\n",
    "            \"from_type\": \"Article\",\n",
    "            \"from\": edge[0],\n",
    "            \"to_type\": \"Article\",\n",
    "            \"to\": edge[1],\n",
    "            \"amendment_order\": edge[2]\n",
    "        })\n",
    "\n",
    "    for key, value in tqdm(iterable=result.items(), desc=\"Save transformed data to JSON\", disable=not verbose):\n",
    "        list_of_dict_to_json(data=value, output_path=os.path.join(output_dir, f\"{key}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transform regulation data: 100%|██████████| 63/63 [00:00<00:00, 1957.37it/s]\n",
      "Save transformed data to JSON: 100%|██████████| 13/13 [00:00<00:00, 85.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare dataset from initial JSON file\n",
    "\n",
    "json_raw_input = os.path.join(\"data\", \"raw\", \"raw.json\")\n",
    "with open(json_raw_input) as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "prepare_regulation_data(\n",
    "    regulation_data=json_data,\n",
    "    output_dir=\"data\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                  :    13  Entity\n",
      "-----------------------------------------------------------------------\n",
      "node_Regulation          :    63  data <class 'list'> of <class 'dict'>\n",
      "node_Observation         :    63  data <class 'list'> of <class 'dict'>\n",
      "node_Definition          :   957  data <class 'list'> of <class 'dict'>\n",
      "node_Consideration       :    63  data <class 'list'> of <class 'dict'>\n",
      "node_Article             :  2423  data <class 'list'> of <class 'dict'>\n",
      "edge_reg_AMENDED_BY      :    26  data <class 'list'> of <class 'dict'>\n",
      "edge_art_AMENDED_BY      :    83  data <class 'list'> of <class 'dict'>\n",
      "edge_REFER_TO            :  1497  data <class 'list'> of <class 'dict'>\n",
      "edge_NEXT_ARTICLE        :  2422  data <class 'list'> of <class 'dict'>\n",
      "edge_HAS_OBSERVATION     :    63  data <class 'list'> of <class 'dict'>\n",
      "edge_HAS_DEFINITION      :   957  data <class 'list'> of <class 'dict'>\n",
      "edge_HAS_CONSIDERATION   :    63  data <class 'list'> of <class 'dict'>\n",
      "edge_HAS_ARTICLE         :  2423  data <class 'list'> of <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# 2. Load dataset from prepared JSON file\n",
    "\n",
    "dataset = load_dataset_from_dir(\"data\")\n",
    "\n",
    "print(f\"{'Dataset':<25}: {len(dataset):>5}  Entity\")\n",
    "for index, data in enumerate(dataset.items()):\n",
    "    key, value = data\n",
    "    print_value = f\"{key:<25}: {len(value):>5}  data {type(value)} of {type(value[0])}\"\n",
    "    if index == 0: print(\"-\" * len(print_value))\n",
    "    print(print_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
